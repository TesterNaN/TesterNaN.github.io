<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程 | TesterNaN的博客</title><meta name="keywords" content="ColossalAI,分布式训练"><meta name="author" content="TesterNaN"><meta name="copyright" content="TesterNaN"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前言（废话）我们都知道，存在若干种方法可以加速我们在训练深度学习模型时的速度，本人大致知道如下几种（具体）：  mlkdnn加速 cuda加速 JIT加速 分布式训练  这些都是成效显著的加速方法，而且属于不同层面的加速。其中基于硬件GPU加速的是目前最主流、效果最好的方案了，在本人自己写框架的时候也发现，深度学习训练过程中也发现，其实可以优化的地方很多：batch size之间可以做并行，单个b">
<meta property="og:type" content="article">
<meta property="og:title" content="使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程">
<meta property="og:url" content="https://testernan.github.io/2023/03/06/%E4%BD%BF%E7%94%A8colossalai%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6%E5%8A%A0%E9%80%9F%E4%BD%A0%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/index.html">
<meta property="og:site_name" content="TesterNaN的博客">
<meta property="og:description" content="前言（废话）我们都知道，存在若干种方法可以加速我们在训练深度学习模型时的速度，本人大致知道如下几种（具体）：  mlkdnn加速 cuda加速 JIT加速 分布式训练  这些都是成效显著的加速方法，而且属于不同层面的加速。其中基于硬件GPU加速的是目前最主流、效果最好的方案了，在本人自己写框架的时候也发现，深度学习训练过程中也发现，其实可以优化的地方很多：batch size之间可以做并行，单个b">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picx.zhimg.com/v2-3ca889cbd3bf0e78a83dc333d244fc45_1440w.jpg?source=172ae18b">
<meta property="article:published_time" content="2023-03-06T08:40:01.000Z">
<meta property="article:modified_time" content="2023-03-06T08:47:29.157Z">
<meta property="article:author" content="TesterNaN">
<meta property="article:tag" content="ColossalAI">
<meta property="article:tag" content="分布式训练">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picx.zhimg.com/v2-3ca889cbd3bf0e78a83dc333d244fc45_1440w.jpg?source=172ae18b"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://testernan.github.io/2023/03/06/%E4%BD%BF%E7%94%A8colossalai%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6%E5%8A%A0%E9%80%9F%E4%BD%A0%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-06 16:47:29'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="TesterNaN的博客" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="http://q1.qlogo.cn/qhis/Q3auHgzwzM73IvhLibJXzW909hiafWzPia31YuSpVJwMEXWF4oqDvbym8azO7buiaibWurpbqyadAw7t1LhOxlJmwmw/0" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">4</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">5</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://picx.zhimg.com/v2-3ca889cbd3bf0e78a83dc333d244fc45_1440w.jpg?source=172ae18b')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">TesterNaN的博客</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-06T08:40:01.000Z" title="发表于 2023-03-06 16:40:01">2023-03-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-06T08:47:29.157Z" title="更新于 2023-03-06 16:47:29">2023-03-06</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="前言（废话）"><a href="#前言（废话）" class="headerlink" title="前言（废话）"></a>前言（废话）</h2><p>我们都知道，存在若干种方法可以加速我们在训练深度学习模型时的速度，本人大致知道如下几种（具体）：</p>
<ul>
<li>mlkdnn加速</li>
<li>cuda加速</li>
<li>JIT加速</li>
<li>分布式训练</li>
</ul>
<p>这些都是成效显著的加速方法，而且属于不同层面的加速。其中基于硬件GPU加速的是目前最主流、效果最好的方案了，在本人自己写框架的时候也发现，深度学习训练过程中也发现，其实可以优化的地方很多：batch size之间可以做并行，单个batch中基于不同的算子实现逻辑，也能做并行；每个训练集的batch之间也能做并行，如何做到高效调度本机GPU的计算资源，或是计算机集群的计算资源，使得整体的并行训练效率尽可能高？</p>
<p>HPC-AI Technology Inc. 和NUS的研究人员共同开发了“夸父”Colossal-AI，该框架提供了一个并行训练框架来尽可能提升（压榨）你的计算资源的使用效率。并自动实现了一些常用的训练技巧。</p>
<blockquote>
<p>由于本人的笔记本前几天又在我relink的时候烂尾了，暂时无法参与本篇文章，所以这篇文章只能展示一下单机单卡的性能压榨，等我把笔记本修好了，再来尝试一下多机多卡分布式训练。</p>
</blockquote>
<hr>
<h2 id="安装、验证"><a href="#安装、验证" class="headerlink" title="安装、验证"></a>安装、验证</h2><h3 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h3><table>
<thead>
<tr>
<th>平台\软件包</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>Win11 WSL2</td>
<td>0.58.3.0</td>
</tr>
<tr>
<td>NVCC</td>
<td>11.3</td>
</tr>
<tr>
<td>Python</td>
<td>3.6.9</td>
</tr>
<tr>
<td>torch</td>
<td>1.10.2+cu113</td>
</tr>
</tbody></table>
<blockquote>
<p>GPU为12G的RTX3060</p>
</blockquote>
<p>请注意：</p>
<ol>
<li>目前colossalai只支持Linux平台下的安装</li>
<li>尽量让你的NVCC版本&gt;&#x3D;11.3</li>
</ol>
<p>不满足第一个条件，则下面pip install时大概率安装失败（今天上午提discussion时开发团队的成员秒回了会在Windows进行试验），不满足第二个条件，有可能失败。</p>
<blockquote>
<p>本人主力机就是windows，可喜的是，目前的WSL2已经支持和宿主机共享显卡驱动了，因此，我在WSL2上完成了实验。</p>
</blockquote>
<h3 id="安装-colossalai"><a href="#安装-colossalai" class="headerlink" title="安装 colossalai"></a>安装 colossalai</h3><p>一句话就可以安装：</p>
<p>building wheel的过程很慢，因为会本地编译与CUDA相关的一些程序。</p>
<p>安装过程可能会出现报错，不过colossalai的setup.py写得很详细了，反正出错了就按照报错信息增加环境变量和安装包就行。</p>
<p>本人实测下来，你最好在colossalai安装前把tensorboard额外下载好，安装程序对tensorboard版本选取有bug。我在另一台电脑上安装时还遇到了交叉编译警告的问题，添加一个环境变量就好了：</p>
<pre><code class="bash">$export TORCH_CUDA_ARCH_LIST=&quot;compute capability&quot;
</code></pre>
<h3 id="验证安装是否成功"><a href="#验证安装是否成功" class="headerlink" title="验证安装是否成功"></a>验证安装是否成功</h3><p>我们使用官方给出的例子进行验证，首先创建环境变量DATA，等一下CIFAR-10数据集会下载在DATA代表的文件夹下。</p>
<p>（更多的例子请看官方的Example仓库 <a target="_blank" rel="noopener" href="https://github.com/hpcaitech/ColossalAI-Examples">GitHub - hpcaitech&#x2F;ColossalAI-Examples: Examples of training models with hybrid parallelism using ColossalAI</a>）</p>
<p>复制下述代码到 eval.py</p>
<pre><code class="python">from pathlib import Path
from colossalai.logging import get_dist_logger
import colossalai
import torch
import os
from colossalai.core import global_context as gpc
from colossalai.utils import get_dataloader
from colossalai.context import Config
from colossalai.amp import AMP_TYPE

from torchvision import transforms
from colossalai.nn.lr_scheduler import CosineAnnealingLR
from torchvision.datasets import CIFAR10
from torchvision.models import resnet34
from tqdm import tqdm

global_config = Config(&#123;
    &quot;BATCH_SIZE&quot; : 128,
    &quot;NUM_EPOCHS&quot; : 2,
    &quot;CONFIG&quot; : &#123;
        &quot;fp16&quot; : &#123;
            &quot;mode&quot; : AMP_TYPE.TORCH
        &#125;
    &#125;
&#125;)

def main():
    colossalai.launch_from_torch(config=global_config)

    logger = get_dist_logger()

    # build resnet
    model = resnet34(num_classes=10)

    # build dataloaders
    print(&quot;loading dataset...&quot;)
    train_dataset = CIFAR10(
        root=Path(os.environ[&#39;DATA&#39;]),
        download=True,
        transform=transforms.Compose(
            [
                transforms.RandomCrop(size=32, padding=4),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[
                    0.2023, 0.1994, 0.2010]),
            ]
        )
    )

    print(&quot;finish loading dataset...&quot;)
    
    test_dataset = CIFAR10(
        root=Path(os.environ[&#39;DATA&#39;]),
        train=False,
        transform=transforms.Compose(
            [
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[
                    0.2023, 0.1994, 0.2010]),
            ]
        )
    )

    train_dataloader = get_dataloader(dataset=train_dataset,
                                      shuffle=True,
                                      batch_size=gpc.config.BATCH_SIZE,
                                      num_workers=1,
                                      pin_memory=True,
                                      )

    test_dataloader = get_dataloader(dataset=test_dataset,
                                     add_sampler=False,
                                     batch_size=gpc.config.BATCH_SIZE,
                                     num_workers=1,
                                     pin_memory=True,
                                     )

    # build criterion
    criterion = torch.nn.CrossEntropyLoss()

    # optimizer
    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)

    # lr_scheduler
    lr_scheduler = CosineAnnealingLR(optimizer, total_steps=gpc.config.NUM_EPOCHS)

    engine, train_dataloader, test_dataloader, _ = colossalai.initialize(model,
                                                                         optimizer,
                                                                         criterion,
                                                                         train_dataloader,
                                                                         test_dataloader,
                                                                         )

    for epoch in range(gpc.config.NUM_EPOCHS):
        engine.train()
        if gpc.get_global_rank() == 0:
            train_dl = tqdm(train_dataloader)
        else:
            train_dl = train_dataloader
        for img, label in train_dl:
            img = img.cuda()
            label = label.cuda()

            engine.zero_grad()
            output = engine(img)
            train_loss = engine.criterion(output, label)
            engine.backward(train_loss)
            engine.step()
        lr_scheduler.step()

        engine.eval()
        correct = 0
        total = 0
        for img, label in test_dataloader:
            img = img.cuda()
            label = label.cuda()

            with torch.no_grad():
                output = engine(img)
                test_loss = engine.criterion(output, label)
            pred = torch.argmax(output, dim=-1)
            correct += torch.sum(pred == label)
            total += img.size(0)

        logger.info(
            f&quot;Epoch &#123;epoch&#125; - train loss: &#123;train_loss:.5&#125;, test loss: &#123;test_loss:.5&#125;, acc: &#123;correct / total:.5&#125;, lr: &#123;lr_scheduler.get_last_lr()[0]:.5g&#125;&quot;, ranks=[0])


if __name__ == &#39;__main__&#39;:
    main()
</code></pre>
<p>然后打开命令行，运行：</p>
<pre><code class="bash">$torchrun --nproc_per_node 1 --master_addr localhost --master_port 8008 eval.py
</code></pre>
<p>由于多机多卡涉及到的通信，所以需要开socket，不过本次是单机，这个参数设了也没啥用，只要确保master_port和本地开启的端口没有冲突就行。</p>
<p>运行效果：</p>
<p><img src="https://pic4.zhimg.com/v2-231c65e880949d17ddce911c30e44b0b_b.jpg"></p>
<p>首次运行需要消耗时间下载CIFAR-10数据集</p>
<p>运行成功。</p>
<hr>
<h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><p>在colossalai的官网上，给出了一套文字教程，个人认为讲得非常清楚：</p>
<p>使用colossalai框架进行训练的大致流程如下：</p>
<p><img src="https://pic3.zhimg.com/v2-916e280351363e1d37bc2e5cf0e2fd3a_b.jpg"></p>
<p>我会大致讲讲使用colossalai构建的每个步骤，这些步骤基本都可以和上述的例子对应起来。所以本人就不再写一个完整的例子了。</p>
<h3 id="config-py-全局配置"><a href="#config-py-全局配置" class="headerlink" title="config.py 全局配置"></a><a target="_blank" rel="noopener" href="http://config.py/">config.py</a> 全局配置</h3><p>colossalai通过一个python文件来作为全局的配置，假设我们把配置文件命名为config.py好了（你当然可以取别的名字），配置的内容可以在后续launch后通过 colossalai.core.global_context 进行访问。</p>
<p>比如我们的config.py是这样的：</p>
<p>那么在整个训练系统中，你可以这么访问它：</p>
<pre><code class="python">import colossalai
from colossalai.core import global_context as gpc

colossalai.launch(config=&#39;./config.py&#39;, ...)

# config.py已经被注册成了对象，直接通过属性值访问
gpc.config.BATCH_SIZE
</code></pre>
<p>除了基本的训练参数，比如批大小，训练轮数外，配置文件和整个训练系统需要使用的并行加速策略直接相关（说直接点，整个colossalai的并行策略就是在config.py中设置的），这部分配置的名字是固定的。</p>
<p>我把和并行策略相关的配置属性值列在下表中，附带对应的教程链接，方便查阅：</p>
<table>
<thead>
<tr>
<th>属性名称</th>
<th>含义</th>
<th>链接</th>
</tr>
</thead>
<tbody><tr>
<td>parallel</td>
<td>并行配置，是一个字典，可配置的子项为数据并行、流水线并行和序列并行</td>
<td><a target="_blank" rel="noopener" href="https://www.colossalai.org/zh-Hans/docs/basics/configure_parallelization">https://www.colossalai.org/zh-Hans/docs/basics/configure_parallelization</a></td>
</tr>
<tr>
<td>fp16</td>
<td>混合精度策略</td>
<td><a target="_blank" rel="noopener" href="https://www.colossalai.org/zh-Hans/docs/features/mixed_precision_training">https://www.colossalai.org/zh-Hans/docs/features/mixed_precision_training</a></td>
</tr>
<tr>
<td>gradient_accumulation</td>
<td>梯度累计次数</td>
<td><a target="_blank" rel="noopener" href="https://www.colossalai.org/zh-Hans/docs/features/gradient_accumulation">https://www.colossalai.org/zh-Hans/docs/features/gradient_accumulation</a></td>
</tr>
<tr>
<td>clip_grad_norm</td>
<td>梯度裁剪范数</td>
<td><a target="_blank" rel="noopener" href="https://www.colossalai.org/zh-Hans/docs/features/gradient_clipping">https://www.colossalai.org/zh-Hans/docs/features/gradient_clipping</a></td>
</tr>
<tr>
<td>gradient_handler</td>
<td>自定义处理梯度同步的类</td>
<td><a target="_blank" rel="noopener" href="https://www.colossalai.org/zh-Hans/docs/features/gradient_handler">https://www.colossalai.org/zh-Hans/docs/features/gradient_handler</a></td>
</tr>
<tr>
<td>MOE_MODEL_PARALLEL_SIZE</td>
<td>一个进程中的混合专家模型数量</td>
<td><a target="_blank" rel="noopener" href="https://www.colossalai.org/zh-Hans/docs/advanced_tutorials/integrate_mixture_of_experts_into_your_model">https://www.colossalai.org/zh-Hans/docs/advanced_tutorials&#x2F;integrate_mixture_of_experts_into_your_model</a></td>
</tr>
</tbody></table>
<p>一种可行的、较为简单的配置如下，很多任务中可以直接复制粘贴：</p>
<pre><code class="python">from colossalai.amp import AMP_TYPE

BATCH_SIZE = 128     # 批次大小
NUM_EPOCHS = 10      # 训练10轮

fp16 = dict(
  mode=AMP_TYPE.TORCH     # AMP后端是pytorh
)

parallel = dict(          # 并行策略，请注意，pipline的取值和tensor的size的乘积为你GPU的数量（此例中为2 * 4 = 8）
    pipeline=2,
    tensor=dict(size=4, mode=&#39;2d&#39;)
)
</code></pre>
<h3 id="colossalai-launch-启动"><a href="#colossalai-launch-启动" class="headerlink" title="colossalai.launch 启动"></a>colossalai.launch 启动</h3><p>通过launch可以将配置文件注入系统中，并初始化各种与网络硬件相关的配置。</p>
<p>关于分布式训练有几个比较重要的几个概念：</p>
<ul>
<li>host: 主训练机的IP</li>
<li>port: 主训练机的端口</li>
<li>host: 训练网络中机器的ID</li>
<li>world size: 网络中机器的数量。</li>
</ul>
<p>将这些参数注入系统的方法有很多种，你可以在<a target="_blank" rel="noopener" href="https://www.colossalai.org/zh-Hans/docs/basics/launch_colossalai">启动 Colossal-AI | Colossal-AI (colossalai.org)</a> 找到。如果你使用的是版本大于1.10的pytorch，可以使用torch自带的脚本torchrun来启动并输入参数：</p>
<p>参数如下：</p>
<ul>
<li>--nproc_per_node : 每个节点GPU的数量</li>
<li>--master_addr : 对应上述 host</li>
<li>--master_port : 对应上述的port</li>
</ul>
<p>倘若你的训练脚本为train.py，本地有三块GPU，只用一台机器训练，那么启动训练的脚本为：</p>
<pre><code class="bash">$torchrun --nproc_per_node 3 --master_addr localhost --master_port 8001 train.py
</code></pre>
<p>上述命令会在该机器上的8001端口开启一个训练服务，如果8001被占用，也可以使用别的端口。</p>
<h3 id="colossalai-initialize-初始化（模型封装）"><a href="#colossalai-initialize-初始化（模型封装）" class="headerlink" title="colossalai.initialize 初始化（模型封装）"></a>colossalai.initialize 初始化（模型封装）</h3><p>在launch之后，我们就不需要关心系统如何调度计算资源了，我们只需要关心单台机器上如何跑训练代码。</p>
<p>除此之外，colossalai还做了一件很nice事情，就是将已有的训练代码进行二次封装，无论用户采用什么模型，什么优化器，什么学习率动态更新算法，什么数据加载器，通过colossalai封装后，后续代码都会变得几乎一模一样。</p>
<p>假设我们已经历经千辛万苦，搞到了训练的几大要素：</p>
<pre><code class="python"># 后端采用pytorch
colossalai.launch_from_torch(config=&quot;config.py&quot;)

# 1. 训练集加载器
train_dataloader = MyTrainDataloader()

# 2. 测试集加载器
test_dataloader = MyTrainDataloader()

# 3. 模型
model = MyModel()

# 4. 优化器
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 5. 损失函数
criterion = torch.nn.CrossEntropyLoss()
</code></pre>
<p>通过colossalai提供的初始化函数可以进行一步封装：</p>
<pre><code class="python"># 返回四个值： engine对象，训练集加载器，测试集加载器，学习率更新器（这不是必须的，从简，不提）
engine, train_dataloader, test_dataloader, _ = colossalai.initialize(
                                                                     model,
                                                                     optimizer,
                                                                     criterion,
                                                                     train_dataloader,
                                                                     test_dataloader,
                                                                    )
</code></pre>
<h3 id="engine封装"><a href="#engine封装" class="headerlink" title="engine封装"></a>engine封装</h3><p>其中的engine就是对模型、优化、损失函数的封装，它同时继承了模型，优化器和损失函数的一堆方法，常用操作我都整理在下表中了：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>engine(inputs)</td>
<td>前向计算，等价于model(inputs)</td>
</tr>
<tr>
<td>engine.zero_grad()</td>
<td>清空梯度，等价于optimizer.zero_grad()</td>
</tr>
<tr>
<td>engine.step()</td>
<td>更新参数，等价于optimizer.step()</td>
</tr>
<tr>
<td>engine.criterion(output, label)</td>
<td>计算损失，等价于criterion(output, label)</td>
</tr>
<tr>
<td>engine.backward(loss)</td>
<td>反向传播，等价于loss.backward()</td>
</tr>
<tr>
<td>torch.save(engine.model.state_dict(), f&#x3D;…)</td>
<td>保存模型</td>
</tr>
<tr>
<td>engine.model.load_state_dict(torch.load(f&#x3D;…))</td>
<td>读取模型</td>
</tr>
<tr>
<td>engine.train()</td>
<td>训练模式，等价于model.train()</td>
</tr>
<tr>
<td>engine.eval()</td>
<td>评估模式，等价于model.eval()</td>
</tr>
</tbody></table>
<blockquote>
<p>请注意，使用engine封装后的模型的state_dict()的每一个key会多出一个”model.”的前缀，它无法直接装载进入一个没有封装成engine的model中，如果你偏要这么做，那么请在load之前对每个key使用lstrip(“model.”)方法进行前缀去除。</p>
</blockquote>
<p>其余的步骤和torch常规训练一致。此处就不赘述了。需要注意的是，由于需要使用torchrun脚本进行启动，请不要直接在jupyter notebook中启动训练代码。</p>
<p>除了engine对象，官方还提供了一个更加高级的封装Trainer，它是对engine的进一步封装。使用Trainer，就能实现Keras风格的直接使用fit函数进行拟合，并且Trainer还提供了使用钩子函数的接口，由于本次实验未使用Trainer，所以留到下一章去讲了，感兴趣的读者可以参考colossalai的官方文档来学习Trainer：<br><a href="https://link.zhihu.com/?target=https://www.colossalai.org/zh-Hans/docs/basics/engine_trainer">如何在训练中使用 Engine 和 Trainer | Colossal-AI</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://testernan.github.io">TesterNaN</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://testernan.github.io/2023/03/06/%E4%BD%BF%E7%94%A8colossalai%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6%E5%8A%A0%E9%80%9F%E4%BD%A0%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/">https://testernan.github.io/2023/03/06/使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://testernan.github.io" target="_blank">TesterNaN的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ColossalAI/">ColossalAI</a><a class="post-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a></div><div class="post_share"><div class="social-share" data-image="https://picx.zhimg.com/v2-3ca889cbd3bf0e78a83dc333d244fc45_1440w.jpg?source=172ae18b" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/03/06/%E4%BD%BF%E7%94%A8stable-diffusion-webui%E9%83%A8%E7%BD%B2NovelAi-Stable-Diffusion-%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B%E3%80%81%E5%91%BD%E4%BB%A4%E8%A7%A3%E9%87%8A%E3%80%81%E5%8E%9F%E7%90%86%E8%AE%B2%E8%A7%A3-colab%E3%80%81windows%E3%80%81Linux/"><img class="next-cover" src="https://pica.zhimg.com/v2-01419a7d6bb6ca634f8bdbb225cc17fe_1440w.jpg?source=172ae18b" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">使用stable-diffusion-webui部署NovelAi/Stable Diffusion 保姆级教程、命令解释、原理讲解(colab、windows、Linux )</div></div></a></div></nav><!--!=partial('includes/third-party/comments/index', {}, {cache: true})--><!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC81ODEwNy8zNDU3MA==">
	<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 --></div><div class="aside-content" id="aside-content"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="287" height="86" src="//music.163.com/outchain/player?type=2&amp;id=2026565329&amp;auto=1&amp;height=66"></iframe><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="http://q1.qlogo.cn/qhis/Q3auHgzwzM73IvhLibJXzW909hiafWzPia31YuSpVJwMEXWF4oqDvbym8azO7buiaibWurpbqyadAw7t1LhOxlJmwmw/0" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">TesterNaN</div><div class="author-info__description">分享一些有意思的文章</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">4</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">5</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/TesterNaN"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">站长很懒，还没有整</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80%EF%BC%88%E5%BA%9F%E8%AF%9D%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">前言（废话）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E3%80%81%E9%AA%8C%E8%AF%81"><span class="toc-number">2.</span> <span class="toc-text">安装、验证</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83"><span class="toc-number">2.1.</span> <span class="toc-text">实验环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-colossalai"><span class="toc-number">2.2.</span> <span class="toc-text">安装 colossalai</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E5%AE%89%E8%A3%85%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F"><span class="toc-number">2.3.</span> <span class="toc-text">验证安装是否成功</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-number">3.</span> <span class="toc-text">基本使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#config-py-%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE"><span class="toc-number">3.1.</span> <span class="toc-text">config.py 全局配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#colossalai-launch-%E5%90%AF%E5%8A%A8"><span class="toc-number">3.2.</span> <span class="toc-text">colossalai.launch 启动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#colossalai-initialize-%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%88%E6%A8%A1%E5%9E%8B%E5%B0%81%E8%A3%85%EF%BC%89"><span class="toc-number">3.3.</span> <span class="toc-text">colossalai.initialize 初始化（模型封装）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#engine%E5%B0%81%E8%A3%85"><span class="toc-number">3.4.</span> <span class="toc-text">engine封装</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/03/06/%E4%BD%BF%E7%94%A8colossalai%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6%E5%8A%A0%E9%80%9F%E4%BD%A0%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/" title="使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程"><img src="https://picx.zhimg.com/v2-3ca889cbd3bf0e78a83dc333d244fc45_1440w.jpg?source=172ae18b" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程"/></a><div class="content"><a class="title" href="/2023/03/06/%E4%BD%BF%E7%94%A8colossalai%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6%E5%8A%A0%E9%80%9F%E4%BD%A0%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/" title="使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程">使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程</a><time datetime="2023-03-06T08:40:01.000Z" title="发表于 2023-03-06 16:40:01">2023-03-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/06/%E4%BD%BF%E7%94%A8stable-diffusion-webui%E9%83%A8%E7%BD%B2NovelAi-Stable-Diffusion-%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B%E3%80%81%E5%91%BD%E4%BB%A4%E8%A7%A3%E9%87%8A%E3%80%81%E5%8E%9F%E7%90%86%E8%AE%B2%E8%A7%A3-colab%E3%80%81windows%E3%80%81Linux/" title="使用stable-diffusion-webui部署NovelAi/Stable Diffusion 保姆级教程、命令解释、原理讲解(colab、windows、Linux )"><img src="https://pica.zhimg.com/v2-01419a7d6bb6ca634f8bdbb225cc17fe_1440w.jpg?source=172ae18b" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用stable-diffusion-webui部署NovelAi/Stable Diffusion 保姆级教程、命令解释、原理讲解(colab、windows、Linux )"/></a><div class="content"><a class="title" href="/2023/03/06/%E4%BD%BF%E7%94%A8stable-diffusion-webui%E9%83%A8%E7%BD%B2NovelAi-Stable-Diffusion-%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B%E3%80%81%E5%91%BD%E4%BB%A4%E8%A7%A3%E9%87%8A%E3%80%81%E5%8E%9F%E7%90%86%E8%AE%B2%E8%A7%A3-colab%E3%80%81windows%E3%80%81Linux/" title="使用stable-diffusion-webui部署NovelAi/Stable Diffusion 保姆级教程、命令解释、原理讲解(colab、windows、Linux )">使用stable-diffusion-webui部署NovelAi/Stable Diffusion 保姆级教程、命令解释、原理讲解(colab、windows、Linux )</a><time datetime="2023-03-06T08:13:05.000Z" title="发表于 2023-03-06 16:13:05">2023-03-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/20/test-my-site/" title="test_my_site"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="test_my_site"/></a><div class="content"><a class="title" href="/2022/06/20/test-my-site/" title="test_my_site">test_my_site</a><time datetime="2022-06-20T11:56:30.000Z" title="发表于 2022-06-20 19:56:30">2022-06-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/20/hello-world/" title="Hello World"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2022/06/20/hello-world/" title="Hello World">Hello World</a><time datetime="2022-06-20T11:14:09.405Z" title="发表于 2022-06-20 19:14:09">2022-06-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By TesterNaN</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://testernan.github.io/2023/03/06/%E4%BD%BF%E7%94%A8colossalai%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6%E5%8A%A0%E9%80%9F%E4%BD%A0%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/'
    this.page.identifier = '2023/03/06/使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程/'
    this.page.title = '使用colossalai分布式框架加速你的深度学习训练速度（一）安装与基本构建流程'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Livere# Valine' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>